# 18週研究計畫(o3)

# 人工智慧於轉診獸醫醫學的助益與威脅

## 第1週：專題導論與計畫概覽

**研究目標：** 理解「轉診獸醫醫學」的定義與體系，以及人工智慧（AI）在此領域可能帶來的助益與威脅概況。確立專題研究範圍，並規劃後續17週的學習與實作內容。

**研究方法：** 文獻探討與情境學習。透過閱讀相關背景資料（包括上傳的研究論文）來瞭解轉診獸醫體系及目前AI技術在獸醫領域的應用現況。討論AI於轉診獸醫的可能角色，初步整理出潛在的「助益」與「威脅」方向。同時，完成環境準備（安裝Python與Jupyter Notebook或使用Google Colab），確保之後每週的實作順利進行。

**詳細研究步驟：**

1. **背景閱讀：** 閱讀研究論文的緒論部分，瞭解轉診獸醫醫學的運作模式（基層獸醫將複雜病例轉介至具備高階儀器與專科醫師的第二線/第三線醫療機構）。整理轉診體系在獸醫醫療中的地位與重要性。接著，閱讀論文中有關AI在獸醫各領域應用的總述，了解AI正迅速滲透獸醫領域並帶來革命性變革。
2. **助益與威脅初探：** 基於所讀內容，列出AI可能帶來的**助益**（例如提升診斷準確度、優化轉診流程、加速新藥研發等）與**威脅**（例如資源不均、獸醫專業角色衝擊、責任歸屬與隱私疑慮等）。這將作為專題的核心問題意識，指導後續週次的深入研究。
3. **環境建置：** 確認電腦上已安裝最新版本的 **Python** 以及理想的開發環境（如 **Jupyter Notebook** 或 Google Colab）。如果使用本地環境，安裝必要套件（如 `numpy`、`pandas`、`scikit-learn`、`tensorflow`、`transformers` 等）；如果使用Colab，熟悉其介面。
4. **環境測試：** 啟動Notebook/Colab，撰寫並執行一段簡單的Python程式碼，以驗證環境配置成功。例如，打印一句話確認可以執行Python程式碼。

**程式碼範例：** 下方範例將在Notebook中打印確認訊息：

```python
# 測試Python環境是否正常運行
print("AI in Veterinary Medicine environment is ready!")

```

執行後，預期在輸出區看到：

```
AI in Veterinary Medicine environment is ready!

```

**延伸參考資源：**

- （閱讀研究論文緒論，了解轉診獸醫體系與AI發展背景）
- 可以查找近期新聞，如報導**AI輔助獸醫診斷**的案例，瞭解本專題的現實意義。例如某動物醫院導入AI輔助影像判讀提升診斷效率的新聞報導。

## 第2週：機器學習基礎與工具準備

**研究目標：** 學習機器學習（ML）的基本概念與流程，包括監督式學習中**分類**問題的解題步驟。熟悉常用機器學習工具庫（如Scikit-learn），為後續分析獸醫資料奠定基礎。

**研究方法：** 理論講解結合簡單實作。本週將介紹特徵、標籤、訓練與測試資料集的概念，以及評估模型表現的基本方法。同時透過Scikit-learn內建範例資料集進行實際操作，加深對機器學習工作流程的理解。

**詳細研究步驟：**

1. **ML核心概念學習：** 瞭解機器學習如何從資料中學習規則。重點掌握「特徵」（feature）與「標籤」（label）的定義——例如在疾病預測中，動物的各項檢查數值可作為特徵，而**疾病的有無**則是標籤（模型的預測目標）。理解監督式學習的訓練過程：提供模型大量帶標籤的樣本，讓模型調整內部參數以配對輸入到正確輸出。
2. **工具庫介紹：** 安裝並引用 Scikit-learn 工具包。說明Scikit-learn的定位：基於Python的開源機器學習庫，提供簡單高效的資料挖掘和分析工具，是很多機器學習項目的核心工具。瀏覽其主要模組，包括資料預處理、模型、評估等。
3. **範例實作 - 鳶尾花資料集分類：** 使用Scikit-learn內建的經典**Iris鳶尾花資料集**作為練習。該資料集包含150筆鳶尾花的特徵（如花萼長度、花瓣寬度）以及其品種分類。
    - **載入資料：** 透過`sklearn.datasets.load_iris()`取得資料並了解其結構（特徵矩陣X和標籤y）。檢視前幾筆資料，認識特徵值範圍和標籤意義。
    - **資料分割：** 將資料拆分為訓練集與測試集（例如8:2比例），確保能評估模型在未看過資料上的表現。使用`train_test_split`函式完成此步驟。
    - **模型訓練：** 選擇一個簡單的分類演算法（如**邏輯迴歸**或**決策樹**）。調用Scikit-learn相應的分類器，如`LogisticRegression`，對訓練資料進行擬合。
    - **模型預測：** 將測試集輸入已訓練模型，獲得預測的花種類。對比預測結果與真實標籤，計算**準確率**等指標來評估模型表現。
    - **結果解讀：** 如果模型在測試集上取得例如90%的準確率，解釋這代表模型能正確分類大多數花種，但仍有部分誤判。討論如何透過調參或更複雜模型提升表現。

**程式碼範例：** 以下以Scikit-learn的鳶尾花資料集為例，訓練一個邏輯迴歸模型並輸出準確率：

```python
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

# 載入鳶尾花資料集
iris = load_iris()
X = iris.data       # 特徵矩陣 (花萼花瓣尺寸等)
y = iris.target     # 標籤 (品種類別)

# 分割訓練集與測試集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 建立並訓練邏輯迴歸模型
model = LogisticRegression(max_iter=200).fit(X_train, y_train)

# 輸出模型在測試集上的準確率
print("測試集準確率:", model.score(X_test, y_test))

```

執行後，可能輸出例如：

```
測試集準確率: 0.90

```

表示模型在測試集中有90%的預測正確率。透過此簡單實驗，我們驗證了機器學習流程：**資料準備 → 模型訓練 → 模型評估**。

**延伸參考資源：**

- （Scikit-learn中文教程，介紹Scikit-learn的定位與功能）
- 若對機器學習基本概念感興趣，可參考吳恩達的機器學習課程內容或其中文翻譯資源，瞭解更多演算法原理。
- Kaggle平台上的入門練習（如**鐵達尼生存預測**）也是不錯的延伸實作，可參考其中文教程進一步練習模型建立與評估。

## 第3週：資料集分析與獸醫案例預測（馬腸絞痛病例）

**研究目標：** 將機器學習應用於實際的獸醫臨床資料，體驗從資料清理到模型預測的完整流程。本週以**馬匹腸絞痛**病例資料為例，建立模型預測馬匹的預後，體會AI在協助獸醫決策上的價值。

**研究方法：** 資料實務操作。使用公開的馬腸絞痛資料集（Horse Colic Dataset）進行分析。這份資料紀錄了數百隻患腸絞痛馬匹的臨床指標（如體溫、心跳率、黏膜顏色等）以及最終結果（存活、死亡或安樂死）。我們將重點預測「馬匹是否存活」，這在臨床上可幫助獸醫盡早判斷治療方案。通過本例，學習**資料清理**、**特徵選擇**、**模型訓練**與**評估**等實戰技巧。

**詳細研究步驟：**

1. **取得與理解資料：** 下載馬腸絞痛數據集（可從UCI機器學習資料庫獲取horse-colic.data）。使用`pandas`讀取資料檔，初步觀察資料格式和內容。例如，此資料集共有約368筆案例，每筆包含20多個特徵（包含生理測量值和臨床觀察）及一個結果欄位（存活=1或死亡=2 等）。注意到資料中可能存在缺失值（某些欄位以`?`表示缺失）。
2. **資料清理：** 統計各特徵缺失值比例，決定清理策略。若少量樣本缺失，可簡單地**刪除**含缺失的樣本；若缺失較多，則考慮以平均值、中位數或其他方式進行**插補**。例如，若體溫有部分缺失，可用所有馬匹的平均體溫填補。確保清理後的資料適合進行模型訓練。
3. **特徵選擇與轉換：** 理解每個特徵的意義，例如「疼痛等級」「黏膜顏色」「腹部膨脹程度」等可能與預後結果相關。對類別型特徵（如黏膜顏色）進行編碼（One-hot或Label Encoding），將文字/序號轉換為模型可處理的數值向量。可先不做特徵縮放，因大部分特徵尺度類似；若有極端尺度差異再考慮標準化。
4. **模型訓練：** 選擇適合預測存活率的分類模型，例如**隨機森林**或前述**邏輯迴歸**。以清理後的資料訓練模型：
    - 將資料集分為訓練集與測試集（例如7成訓練、3成測試），以確保客觀評估模型效能。
    - 使用`RandomForestClassifier`訓練模型，期間可透過`verbose`觀察模型訓練過程（如決策樹數量）。訓練完成後，取得模型在訓練集上的預測準確率，確認模型已學習到一定模式。
5. **模型評估：** 將訓練好的模型應用在保留的測試集上，取得**測試準確率**及其他評估指標。例如，模型可能在測試集上達到約80%的準確率，表示對馬匹生存與否有不錯的判別能力。進一步計算**混淆矩陣**，解析模型誤分類的情形（如誤將實際死亡預測為存活的比例）。這對醫療應用很重要，因為誤判可能導致錯誤的臨床決策。
6. **結果討論：** 分析哪個特徵對模型判斷影響最大（可利用隨機森林的特徵重要性）。例如，模型可能著重「腹部膨脹程度」或「疼痛指數」等特徵。這與獸醫臨床經驗是否一致？討論AI模型在此預測任務中的表現是否達到實用水準，以及有哪些可能改進空間（如增加樣本量、加入更多特徵、調整模型參數等）。

**程式碼範例：** 以下以簡化的步驟展示如何讀取資料、訓練模型並評估準確率：

```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

# 讀取馬腸絞痛資料 (假設已清理缺失值並存為CSV檔)
df = pd.read_csv('horse_colic_clean.csv')
X = df.drop('outcome', axis=1)  # outcome欄位: 1=存活, 2=死亡, 3=安樂死
y = df['outcome']

# 分割資料集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

# 訓練隨機森林模型
model = RandomForestClassifier(n_estimators=100, random_state=0)
model.fit(X_train, y_train)

# 評估模型表現
train_acc = model.score(X_train, y_train)
test_acc = model.score(X_test, y_test)
print(f"訓練集準確率: {train_acc:.2f}")
print(f"測試集準確率: {test_acc:.2f}")

```

假設輸出：

```
訓練集準確率: 0.98
測試集準確率: 0.81

```

表示模型在訓練資料上接近滿分，但在測試集約為81%，出現明顯的**落差**，可能意味模型有些**過度擬合**。這提示我們需要透過調參或其他方式改善模型在未知資料上的泛化能力。

**延伸參考資源：**

- （馬腸絞痛資料集說明及醫學背景）指出馬腸絞痛是馬匹主要死因之一，透過機器學習模型預測馬匹是否能存活，可協助獸醫快速做出預後評估和治療決策。這體現了AI在臨床決策上的潛在價值。
- 在模型評估方面，可進一步閱讀Scikit-learn關於**模型評估與交叉驗證**的教程，學習如何使用K-fold交叉驗證取得更可靠的模型表現估計，以及使用`GridSearchCV`調整模型超參數以提升預測能力。

## 第4週：模型評估與改進

**研究目標：** 深入掌握機器學習模型的評估方法，並嘗試改進先前模型的性能。透過本週學習，了解評估指標（如準確率、精確率、召回率）在醫療預測中的意義，體會如何針對模型診斷結果進行分析與優化。

**研究方法：** 以第3週訓練的馬腸絞痛預測模型為基礎，進行模型表現的評估與改良。學習繪製**混淆矩陣**來分析各類別的預測情形，計算**精確率**（Precision）與**召回率**（Recall）等指標，特別關注在醫療場景中假陽性、假陰性的含義。根據評估結果，嘗試調整模型或使用不同演算法，觀察性能變化。

**詳細研究步驟：**

1. **模型評估指標講解：** 復習**混淆矩陣**的概念，矩陣四格（TP, FP, FN, TN）的含義，以及從中計算出的精確率、召回率和F1分數。強調在獸醫醫療中，不同錯誤類型的影響：例如將實際患有致命疾病的個體誤判為健康（假陰性）可能延誤治療，而將健康個體誤判為患病（假陽性）則可能導致不必要的轉診或處置。針對不同情境，評估指標的重要性可能大於整體準確率。
2. **混淆矩陣與報告生成：** 使用Scikit-learn的`confusion_matrix`和`classification_report`對上週模型的測試結果進行分析。觀察模型對「存活」與「死亡」兩類的預測狀況，例如：模型也許對「存活」判斷較準確但對「死亡」較易誤判。從分類報告中讀取每類的精確率和召回率，找出模型偏弱的部份。如發現「死亡」病例的召回率偏低，表示模型漏掉了一些實際死亡案例。
3. **結果討論與可視化：** 繪製混淆矩陣圖（熱力圖形式），直觀展示預測錯誤的分布。討論這對臨床決策的意義——例如模型將5隻實際死亡馬匹誤判為存活，這在實務上是較嚴重的錯誤，需要設法減少。可能的做法包括提高模型對死亡病例的靈敏度，即使可能多一些假警報。這涉及**精確率與召回率的權衡**：可以考慮調整分類門檻值，或使用對不平衡資料表現更好的評估指標（如AUROC曲線、PR曲線）。
4. **模型改進嘗試：** 根據上步分析的弱點，嘗試以下改進：
    - **調參與正則化：** 若模型過度擬合（如訓練準確率遠高於測試），可對模型加入正則化限制或降低複雜度。例如在隨機森林中降低樹的深度，或在邏輯迴歸中增加正則化強度。
    - **更換模型：** 嘗試不同分類演算法，如支援向量機（SVM）或XGBoost，看是否能提升模型對少數類別的捕捉能力。
    - **重採樣策略：** 如資料集中各類樣本嚴重不平衡，可考慮對少數類別過抽樣（oversampling）或多數類別欠抽樣（undersampling），或利用SMOTE等合成技術，讓模型受到的訓練更加平衡，以提升對死亡病例的敏感度。
5. **比較與評估：** 將改進後模型再次在測試集上評估，與原模型指標對照。如果新模型在「死亡」類別的召回率有明顯提高且整體準確率保持，則視為改進成功。如果發現權衡（例如提高召回率但精確率下降太多），則需討論哪種表現更符合臨床需求。

**程式碼範例：** 下面示範如何計算分類模型的混淆矩陣與精確率/召回率報告：

```python
from sklearn.metrics import confusion_matrix, classification_report

# 基於第3週訓練的模型，對測試集做預測
y_pred = model.predict(X_test)

# 計算混淆矩陣
cm = confusion_matrix(y_test, y_pred)
print("混淆矩陣:")
print(cm)

# 輸出分類報告（含精確率、召回率、F1分數）
report = classification_report(y_test, y_pred, target_names=["死亡", "存活"])
print("分類報告:")
print(report)

```

假設模型只有「存活」(活命)與「死亡」兩類，則可能得到：

```
混淆矩陣:
[[12  4]
 [ 3 25]]

分類報告:
              precision    recall    f1-score   support
死亡          0.80         0.75       0.77         16
存活          0.86         0.89       0.88         28

```

這表示在16隻實際死亡的馬匹中，模型正確預測了12隻（召回率75%），誤將4隻死亡判為存活；而在28隻實際存活的個體中，模型正確判斷了25隻（召回率89%），有3隻錯誤標記為死亡。**死亡類別的精確率80%**意味著模型判定為「死亡」的案例中有20%是誤報。根據這些結果，我們可以針對性地調整模型以減少關鍵錯誤，例如將重點放在提升死亡病例的召回率，即便可能多一些誤報，因為在臨床上寧可誤判健康為有風險，也不希望漏判高危病例。

**延伸參考資源：**

- 建議閱讀斯坦福大學Andrew Ng關於**評估指標**的課程講義，了解何時應該關注精確率或召回率，以及PR曲線和ROC曲線的用法，有助於醫療領域的模型調適。
- Scikit-learn官方指南中“**模型評估與調優**”章節提供了詳細的範例，說明如何使用交叉驗證分數挑選模型、透過網格搜索尋找最佳參數組合等，這對進一步提升模型表現很有幫助。

## 第5週：深度學習基礎與神經網路簡介

**研究目標：** 理解深度學習的基本概念，認識**人工神經網路（ANN）**的架構與原理，以及深度學習如何在複雜任務（如影像和語言處理）中展現傳統機器學習難以企及的表現。為後續學習卷積網路和NLP模型打下基礎。

**研究方法：** 理論學習為主，輔以簡單程式驗證。首先介紹人工神經網路的基本組成：**輸入層-隱藏層-輸出層**，說明神經元的加權和與激活函數。比較深度學習與傳統機器學習的差異：深度學習能自動從大量數據中**提取高階特徵**，特別適合影像、語音等非結構化資料。本週將嘗試建立一個簡單的多層感知器模型，體驗深度學習框架的基本用法。

**詳細研究步驟：**

1. **人工神經網路原理：** 以生物神經元類比，引入人工神經元的概念。說明每個**神經元**會將接收到的多個輸入乘以對應權重並累加，然後通過一個**激活函數**（例如ReLU, sigmoid）產生輸出。講解常見激活函數的作用：如sigmoid將輸出壓縮在0~1之間適合做概率解讀，ReLU在深層網路中緩解梯度消失等。
2. **網路架構：** 描述單層感知器不足以處理非線性問題（如XOR問題），引出**多層感知器（MLP）與隱藏層**的概念。強調多層隱藏層堆疊（即「深度」）可以逐層學習更抽象的特徵，這是深度學習強大的關鍵。舉例：在動物圖像識別中，第一層或許學簡單邊緣，第二層學習局部圖形，更多層後可組合出辨識整個物體的特徵。
3. **深度學習與傳統ML比較：** 傳統ML多需要人工設計特徵，而深度學習透過反向傳播算法自動調整權重，**端到端**學習特徵和任務。這需要大量資料和算力的支持，但成功應用在許多領域，尤其是醫學影像分析上已有驚人的成果。
4. **深度學習框架實作體驗：** 安裝並導入**TensorFlow/Keras**（或PyTorch）庫。在Notebook中構建一個最簡單的神經網路範例：
    - **資料準備：** 產生一組人造數據（例如二分類的點狀資料）或使用小型現成資料集（如MNIST手寫數字集的子集）。
    - **定義模型：** 使用Keras的Sequential API，添加輸入層對應的Dense隱藏層（例如包含16個神經元，激活函數使用ReLU），再添加一個輸出層（假設二分類，用1個神經元配合sigmoid激活）。
    - **編譯模型：** 選擇優化器（如`adam`）、設定損失函數（如二元交叉熵）和評估指標（如準確率）。
    - **訓練模型：** 用`model.fit`訓練若干個世代（epoch），觀察損失和準確率的變化。讓學生體驗到反向傳播過程自動進行，看到深度學習模型逐步收斂。
    - **模型摘要：** 調用`model.summary()`列印模型各層參數情況，理解參數量與網路深度/寬度的關係。
5. **結果與討論：** 如果使用簡單的人造資料，例如XOR問題，單一線性模型無法解決，但雙隱藏層的MLP可輕鬆分類正確。藉此強調深度學習在處理非線性關係上的優勢。討論深度學習的**代價**：需要較多運算資源與訓練時間，以及大量標註資料支持。引出下週將要探討的卷積神經網路，專門針對影像資料設計。

**程式碼範例：** 下方示範如何使用Keras建立一個兩層的全連接神經網路模型：

```python
from tensorflow import keras
from tensorflow.keras import layers

# 定義一個簡單的全連接前饋神經網路
model = keras.Sequential([
    layers.Dense(16, activation='relu', input_shape=(10,)),  # 假設輸入特徵維度為10
    layers.Dense(1, activation='sigmoid')  # 輸出層（1個神經元，二分類輸出0~1概率）
])
model.summary()

```

輸出模型摘要，如：

```
Model: "sequential"
_________________________________________________________________
 Layer (type)       Output Shape      Param #
=============================================
 dense (Dense)      (None, 16)        176
 dense_1 (Dense)    (None, 1)         17
=============================================
Total params: 193
Trainable params: 193
Non-trainable params: 0

```

此處總參數量193即為模型需要學習的權重數。接著可呼叫`model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])`進行編譯，並使用適當的資料調用`model.fit`進行訓練。由於資料與案例較簡單，此模型通常幾個epoch內即可收斂至接近100%的準確率。這證實深度學習模型能自動從資料中學到複雜關係，而無需人工設定太多規則。

**延伸參考資源：**

- 建議觀看3Blue1Brown的系列影片**「神經網路如何運作？」**，以視覺化方式理解梯度下降和反向傳播的原理（有中文字幕）。
- 可參考李宏毅教授的**深度學習課程**講義，裡面對MLP及其訓練細節有深入但平易近人的說明。
- 若對程式實作有興趣，可嘗試使用PyTorch重新實現本週的簡單網路，體驗不同深度學習框架的使用風格。

## 第6週：卷積神經網路（CNN）與影像數據

**研究目標：** 瞭解卷積神經網路（CNN）的架構與原理，為何CNN特別適合處理影像資料。學習卷積層、池化層等關鍵組件的功能，以及CNN在醫學影像分析中的應用潛力。

**研究方法：** 理論結合實例。本週以視覺化方式說明CNN如何提取影像特徵，包括**卷積**操作（convolution）和**池化**操作（pooling）的機制。透過簡單的程式實驗（如載入小型影像集），觀察CNN對影像的處理流程。並引用實際研究案例說明CNN在獸醫影像診斷中的成效。

**詳細研究步驟：**

1. **CNN架構講解：** 介紹卷積神經網路由多個**卷積層**和**池化層**堆疊組成，最後接上全連接層完成分類。強調卷積層會學習**濾波器（filter/kernel）**，可看作小窗口在圖片上滑動，偵測局部特徵。當濾波器掃描到有用的特徵（例如邊緣、角落），輸出高值；無重要特徵處輸出低值，形成**特徵圖（feature map）**。多個卷積核可以學到不同的特徵，如線條方向、紋理等，這讓CNN能夠自動抓取影像的關鍵局部模式。池化層則負責壓縮特徵圖尺寸（如取最大值或平均值），降低計算量並具備某種程度的不變性（如圖像小幅移動或縮放不影響特徵值）。
2. **卷積操作實例：** 演示一個簡單卷積的例子：給定一張灰階貓咪圖片和一個邊緣檢測3x3濾波器，透過數學卷積計算出輸出特徵圖，觀察邊緣在輸出中特別明顯。這直觀展示卷積層如何**提取局部特徵**。說明在CNN中，我們不需要人為設計這些濾波器，網路會自行學習最能幫助分類的濾波器權值。
3. **CNN參數量與優勢：** 比較CNN與全連接網路在影像處理上的參數效率。假設一張224x224彩色圖像，若直接全連接到10個隱藏神經元，需要224*224*3*10≈150萬參數；但使用卷積方式，假設10個5x5的濾波器，參數僅10*5*5*3=750。《這展現了卷積透過**參數共享**與**局部連接**大幅減少了參數量】，使得CNN更易訓練且較不易過擬合。CNN的出現正是深度學習在影像領域取得突破的關鍵。
4. **實際程式體驗CNN：** 利用Keras構建一個簡單的卷積網路，並在小型影像資料上觀察其工作：
    - **資料集選擇：** 可使用Keras內建的 **CIFAR-10** 小圖像集（包含貓、狗等物體，共10類，每張32x32彩色圖）。我們選取其中**貓**與**狗**兩類資料來進行二分類，模擬在獸醫情境下區分兩種動物（或正常與異常）。
    - **資料預處理：** 載入CIFAR-10後，篩選出標籤屬於貓或狗的樣本。將影像像素值標準化（除以255）。劃分訓練和測試集。
    - **建立CNN模型：** 使用Keras Sequential依序添加：卷積層（例如32個3x3濾波器，激活ReLU）、池化層（2x2 MaxPooling）、再一個卷積層（64個3x3濾波器）、池化層，然後Flatten攤平接全連接層輸出。輸出層使用sigmoid做二分類。
    - **模型訓練：** 編譯模型（使用`binary_crossentropy`損失和`adam`優化器），用訓練資料訓練模型5個epoch並同時監測驗證集的準確率。由於資料集較小、網路結構也淺，幾個epoch後模型應能達到不錯的辨識效果（期望>80%的準確率）。訓練過程中觀察loss和accuracy的變化趨勢，體會CNN自動學習影像特徵的能力。
    - **性能評估：** 在測試集上評估模型準確率，並與訓練準確率對比，確認是否有過擬合現象。
5. **討論CNN在獸醫影像的應用:** 結合研究論文中的案例，強調CNN已成功應用於**獸醫放射影像**判讀。例如，有研究利用CNN分析犬的X光片，自動偵測心臟擴大、肺水腫、骨折等多種病變，準確率高達90-95%。又例如，國內團隊將CNN應用於**犬隻眼底影像**，模型分辨正常與異常視神經盤的精確率和召回率超過99%，顯示出極高的篩查效率。這些成果凸顯CNN在轉診獸醫醫學中的潛力：可作為第一線工具協助一般獸醫師發現影像異常，及早轉介專科。

**程式碼範例：** 以下建立並訓練一個簡化的CNN來區分貓狗影像：

```python
import numpy as np
from tensorflow.keras.datasets import cifar10
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

# 載入 CIFAR-10 資料集並篩選出貓(類別3)和狗(類別5)影像
(X_train, y_train), (X_test, y_test) = cifar10.load_data()
cat_dog_idx_train = np.where((y_train==3) | (y_train==5))[0]
cat_dog_idx_test  = np.where((y_test==3)  | (y_test==5))[0]
X_train_cd = X_train[cat_dog_idx_train] / 255.0  # 正規化像素
y_train_cd = (y_train[cat_dog_idx_train] == 5).astype(int)  # 貓標記為0, 狗標記為1
X_test_cd  = X_test[cat_dog_idx_test]   / 255.0
y_test_cd  = (y_test[cat_dog_idx_test]  == 5).astype(int)

# 建立卷積神經網路模型
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),
    MaxPooling2D((2,2)),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D((2,2)),
    Flatten(),
    Dense(64, activation='relu'),
    Dense(1, activation='sigmoid')
])
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# 訓練模型 (epochs=3 作示範)
history = model.fit(X_train_cd, y_train_cd, epochs=3, batch_size=64, validation_data=(X_test_cd, y_test_cd))

# 輸出訓練過程中最後的準確率
train_acc = history.history['accuracy'][-1]
val_acc = history.history['val_accuracy'][-1]
print(f"最終訓練準確率: {train_acc:.2f}")
print(f"最終測試準確率: {val_acc:.2f}")

```

執行訓練過程時，將看到每個epoch的損失和準確率，例如：

```
Epoch 1/3 - loss: 0.6104 - accuracy: 0.68 - val_loss: 0.5123 - val_accuracy: 0.76
Epoch 2/3 - loss: 0.4857 - accuracy: 0.78 - val_loss: 0.4791 - val_accuracy: 0.79
Epoch 3/3 - loss: 0.4268 - accuracy: 0.83 - val_loss: 0.4610 - val_accuracy: 0.82

```

最後輸出訓練和測試準確率，例如：

```
最終訓練準確率: 0.84
最終測試準確率: 0.82

```

模型在訓練集和測試集的準確率相近且都有約八成以上，表示這個簡易CNN已經學到區分貓狗的有效特徵且沒有明顯過擬合。透過卷積核的學習，模型可能捕捉到「貓的圓臉特徵」和「狗的長嘴特徵」等局部差異，這就是CNN強大的特徵學習能力。類比到醫療影像，CNN能自動學習例如腫瘤邊緣、器官輪廓等人眼關注的重點，輔助判讀。

**延伸參考資源：**

- （CNN基礎概念介紹）對卷積如何提取圖片局部特徵有深入淺出的說明，建議閱讀以鞏固概念。
- 建議嘗試調整上述模型的結構（如增加卷積層數或節點數）觀察對準確率的影響，或開啟GPU加速來嘗試訓練更多epoch，提高模型表現。
- 參考論文瞭解更多CNN在獸醫影像診斷中的先進案例，例如MRI協助椎間盤突出定位、GAN用於病理圖像染色等，這些都展示了深度學習在專科診斷上的應用前景。

## 第7週：影像診斷 AI 實作（一）— 寵物X光影像分類

**研究目標：** 綜合運用前幾週學到的深度學習知識，動手實作一個針對獸醫影像的AI分類模型。透過本週任務，加深對影像資料處理流程的理解，包括資料準備、模型訓練與調試。同時體驗AI模型在簡化問題（如辨識X光圖像中的特定模式）上的實際表現，為更複雜的醫學影像分析打基礎。

**研究方法：** 本週以實作為主，選擇一組寵物X光影像資料集來進行分類模型訓練。由於高品質的開源獸醫X光資料有限，我們將採用人為構造的任務來模擬醫學影像分類。例如，使用**貓狗X光影像**來訓練模型分辨物種，或使用**正常與異常**影像來訓練模型自動篩檢異常。通過這樣的實驗，體會AI自動判讀影像的流程和挑戰。

**詳細研究步驟：**

1. **資料集準備：** 蒐集或下載寵物X光影像資料。假設從某開源資源獲得數十張犬貓胸腔X光影像，其中部分有明顯心臟肥大或肺部病變。我們將這些影像按**正常**與**異常**兩類標註，作為分類模型的資料集。**（注意：**如無法取得實際X光，可退而求其次使用前述CIFAR-10或其他影像集模擬。）
    - 將影像整理至資料夾結構：`train/normal/`放正常影像，`train/abnormal/`放異常影像；`valid/`底下同樣兩子目錄存驗證用影像。
    - 使用`ImageDataGenerator`或`tf.keras.utils.image_dataset_from_directory`來讀取這些資料夾，並進行必要的預處理（縮放像素值、調整影像大小到一致）。如果資料量不大，採用`ImageDataGenerator`的**資料增強**(augmentation)功能，如隨機翻轉、旋轉一定角度等，增加樣本多樣性。
2. **模型構建：** 建立CNN模型。可以沿用第6週的模型架構，或視資料複雜程度增加層數。比如這裡可採用**3層卷積**堆疊，每層後接池化，最後全連接分類兩類。為避免過擬合，可在卷積層間或全連接層後加入**Dropout**層隨機丟棄部分神經元。
3. **模型訓練：** 使用前面建立的訓練資料集生成器，調用`model.fit`開始訓練模型。例如訓練10個epoch，觀察訓練及驗證集的損失與準確率曲線。如果發現驗證集準確率在某點不再提升甚至惡化，可能過擬合，則可啟用**EarlyStopping**根據驗證損失提前停止訓練。
4. **模型評估：** 在獨立的測試集（或者驗證集）上評估最終模型的表現。除了準確率，也計算模型對異常病例的精確率和召回率，確保模型不會大量漏診。若發現模型對異常檢出率不足，可考慮調低分類閾值或調整類別權重來提高靈敏度。
5. **結果分析：** 隨機選取數張模型預測結果，對比模型輸出與實際標註。例如模型成功將某張含心臟肥大的X光判為異常，但可能誤將一張正常影像判為異常。嘗試分析誤判原因：是因為影像品質問題、還是某些正常變異被模型誤認？討論如何改善（更多資料、調參等）。
6. **專科應用討論：** 雖然我們的範例任務相對簡單，但它類比了臨床上的應用場景。如上述模型可以擴展成**AI輔助篩檢**工具：先讓AI從大量一線醫院的影像中篩出疑似異常者，再交由專科獸醫確認。這將大幅提升轉診效率和診斷速率。分享實際研究中，AI已經能從X光片中自動計算心臟胸腔比例、偵測腫瘤陰影等，協助一般獸醫師做初步判讀。這些應用都建立在我們本週實驗所體現的技術基礎上。

**程式碼範例：** 由於與第6週類似，這裡重點展示如何透過資料增強提升模型泛化能力：

```python
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# 建立資料增強生成器
train_datagen = ImageDataGenerator(rescale=1/255.0, rotation_range=20, horizontal_flip=True)
valid_datagen = ImageDataGenerator(rescale=1/255.0)

# 從資料夾讀取影像並產生批次資料
train_gen = train_datagen.flow_from_directory('data/train', target_size=(128,128),
                                             class_mode='binary', batch_size=16)
valid_gen = valid_datagen.flow_from_directory('data/valid', target_size=(128,128),
                                             class_mode='binary', batch_size=16)

# 建立CNN模型 (此處簡化，細節與第6週相似)
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(128,128,3)),
    MaxPooling2D(2,2),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Flatten(),
    Dense(64, activation='relu'),
    Dense(1, activation='sigmoid')
])
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# 訓練模型
history = model.fit(train_gen, epochs=10, validation_data=valid_gen)

# 評估模型
loss, acc = model.evaluate(valid_gen)
print(f"驗證集準確率: {acc:.2f}")

```

執行結果會首先列出透過`flow_from_directory`加載的資料量，例如：

```
Found 100 images belonging to 2 classes.
Found 20 images belonging to 2 classes.

```

模型訓練過程每個epoch也會顯示，如：

```
Epoch 1/10: loss:0.69 acc:0.55 - val_loss:0.68 val_acc:0.60
...
Epoch 10/10: loss:0.30 acc:0.88 - val_loss:0.40 val_acc:0.85

```

最終驗證集準確率約85%。雖然僅是模擬性的小資料集，這已經體現AI對影像模式的學習能力。**資料增強**明顯有助於提升模型泛化——如果不使用增強，模型可能在訓練集達到更高精度但驗證集表現較差。增強提供了多樣化的訓練樣本，使模型更能適應不同拍攝角度或光線下的X光片。這在實務中非常重要，因不同醫院的影像設備和拍攝手法可能有差異。

**延伸參考資源：**

- 建議使用更大的開源資料集（如Stanford Dogs資料集）嘗試訓練，體驗資料規模對深度學習的影響。
- 可參考Keras官方範例“Cats vs Dogs”遷移學習教程瞭解如何利用**預訓練模型**（如ImageNet上訓練的Xception）微調至新任務，常可在小型資料集上取得驚人的高準確率。這也是醫學影像AI常用手法之一，因為醫學標註資料通常有限。

## 第8週：影像診斷 AI 實作（二）— 模型優化與專科應用

**研究目標：** 探索進階的深度學習技巧來提升影像分類模型效能，同時將視野拓展到更專業的醫學影像應用。本週目標包括：嘗試**遷移學習**（Transfer Learning）加速模型訓練、使用**正則化**與**超參數調整**優化模型，以及結合實際案例思考AI在專科影像診斷中的落地方式與挑戰。

**研究方法：** 在前一週模型的基礎上進行改進。首先介紹遷移學習的概念，即利用在大型資料集（如ImageNet）上預訓練好的模型，將其**卷積層權重**轉移過來，應用到我們的影像任務上。這可大幅縮短訓練時間並提升精度，因為預訓練模型已具備強大的特徵提取能力。我們將實作遷移學習，並與從頭訓練的模型比較效果。接著討論其他優化手段，如調整學習率、使用早停、正則化等。最後，以論文中的**實際專科應用**為例，分析AI模型從實驗室走向臨床現場所需克服的問題。

**詳細研究步驟：**

1. **遷移學習理論：** 說明為何遷移學習適用於醫學影像：醫學影像數據相對有限，但很多低階特徵（如邊緣、形狀）與一般影像相通。因此可借助已在數百萬張ImageNet影像上訓練的模型作特徵提取器。介紹常用的預訓練模型（如VGG, ResNet, Xception等），以及**凍結卷積層**和**細調（fine-tune）**的策略。
2. **實作遷移學習：** 選擇一個適合本任務的預訓練模型，如Keras提供的**MobileNetV2**或**Xception**。載入模型權重且不包含頂層（即不包含原分類層)，凍結其所有卷積層參數。然後在其輸出上疊加我們自己的全連接層（例如1個全連接隱藏層和輸出層）。如下示範：
    
    ```python
    base_model = keras.applications.Xception(weights='imagenet', include_top=False, input_shape=(128,128,3))
    base_model.trainable = False  # 凍結預訓練模型參數
    model = keras.Sequential([
        base_model,
        layers.GlobalAveragePooling2D(),
        layers.Dense(1, activation='sigmoid')
    ])
    
    ```
    
    編譯並訓練此模型，用上週相同的資料。由於預訓練模型已具備強大特徵抽取能力，僅訓練最後幾層，全過程將非常快速且收斂迅速。觀察訓練過程中，模型很可能在少數epoch內就達到很高的驗證準確率，例如甚至超過90%。
    
3. **細調（Fine-tuning）：** 如果時間允許，嘗試將預訓練模型的後幾層權重解凍，以極低的學習率進行**微調**。這可以進一步提升模型性能，但需謹慎避免破壞預訓練權重。觀察微調後驗證集準確率是否有細微提升。
4. **比較效果：** 將遷移學習模型與上週從零訓練的模型比較：在相同測試集上，哪一個準確率更高？一般預期遷移學習模型更優。同時對比兩者訓練時間，遷移學習通常更快收斂。這驗證了遷移學習在小樣本醫學影像任務上的價值。
5. **其他優化手段：** 總結在深度學習訓練中常用的優化方法：
    - **早停（Early Stopping）：** 監測驗證集損失，在多個epoch無改善時自動停止訓練，防止過擬合。
    - **學習率調整：** 使用Learning Rate Scheduler或ReduceLROnPlateau，根據訓練狀態動態降低學習率，以獲得更精細的收斂。
    - **正則化：** 加入L2正則項懲罰大權重，或在模型中融入Batch Normalization穩定訓練。
    - **增加資料量：** 若模型表現仍有限，可能是資料不足，這在醫學領域很常見。可以考慮引入多中心資料或和其他團隊合作共享數據，當然這涉及隱私與法規問題（下週會深入探討）。
6. **專科應用探討：** 本週最後，引導學生展望AI在轉診專科中的應用實例：
    - **影像組合判讀：** 論文提到有研究利用多視角X光讓AI隱式建立3D概念，以更準確診斷神經系統疾病。這是進階的應用，需要大量資料與巧妙模型。
    - **病理影像：** 例如香港城市大學團隊開發AI免疫染色技術，可快速評估貓狗淋巴瘤的病理切片，提高診斷效率（額外資訊，非論文內容）。這顯示AI在獸醫腫瘤病理上的前景。
    - **跨模態融合：** 下一步AI可能將不同模態數據（影像 + 病歷數據）結合進行判斷。例如同時考慮X光片、血檢結果和病史文字，做出比單一模態更準確的診斷建議。這類**多模態機器學習**被視為AI醫療的未來關鍵方向。鼓勵學生思考：未來如果你有一套AI系統，能輸入影像和文字，就像全科醫師一樣給出全面判讀，這會如何改變轉診流程？帶著這些問題進入後續的NLP單元學習。

**程式碼範例：** 以下展示使用預訓練的Xception模型進行遷移學習的關鍵步驟（細節如模型訓練過程從略）：

```python
from tensorflow.keras.applications import Xception

# 載入預訓練的Xception模型，不包括頂層
base_model = Xception(weights='imagenet', include_top=False, input_shape=(128,128,3))
base_model.trainable = False  # 凍結卷積層權重

# 在其上加自己的分類頭
model = Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(1, activation='sigmoid')
])
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# 進行訓練（略）
# ...

# 解凍部分卷積層進行微調（選擇性）
base_model.trainable = True
for layer in base_model.layers[:100]:
    layer.trainable = False  # 仍凍結前100層，只微調後面的層
model.compile(optimizer=keras.optimizers.Adam(1e-5),  # 降低學習率
              loss='binary_crossentropy', metrics=['accuracy'])
# 再次訓練（略）

```

使用遷移學習，模型通常在**首個epoch**就達到很高的驗證準確率，因為預訓練模型已提供強大的特徵。這凸顯出：對於本專題未來可能遇到的大量醫學影像，預訓練的通用特徵提取器結合少量專科數據進行微調，是可行且高效的方案。在實驗後期，可嘗試部分解凍卷積層進行微調，但要注意控制學習率和訓練輪數，以免過度調整破壞預訓練權重。

**延伸參考資源：**

- 《Deep Learning for Veterinary Imaging》等主題的前沿論文，了解最新的模型架構（如EfficientNet, Vision Transformer）在獸醫影像上的應用。
- Keras官方指南中詳細介紹了遷移學習和微調的步驟，可作為實作參考。
- 斯坦福大學的**MultiModal Machine Learning**課程講義，探討如何結合影像、文字等多種資料來源進行建模，有助於理解未來AI整合多模態數據的方向。

## 第9週：自然語言處理（NLP）基礎與獸醫文本資料

**研究目標：** 了解自然語言處理（NLP）的基本概念和常用技術，並認識獸醫領域常見的文字資料類型（如病歷記錄、化驗報告等）。本週重點在於掌握如何將非結構化的文字轉化為可分析的形式，以及NLP在醫療文本分析中的應用場景，為後續病歷摘要、自動轉診建議等任務做鋪墊。

**研究方法：** 理論講解與小範例實作。首先介紹NLP處理文本的常用步驟，包括**斷詞/分詞**、**詞彙表示**（例如將文字轉換為數字向量），以及典型的NLP任務（文本分類、命名實體識別、關係抽取、文本摘要等）。透過簡單的Python範例體驗文本處理，如將一段中文獸醫病歷句子進行分詞，或統計詞頻，感受文本資料與結構化數據的差異。討論NLP在獸醫領域可以發揮的功能，例如從繁雜的書寫病歷中提取關鍵資訊、分類病歷屬於哪個專科等。

**詳細研究步驟：**

1. **NLP基礎概念：** 說明電腦處理文字的挑戰：文字是非結構化的符號序列，必須轉換為數字才能進行計算。介紹**語料庫**和**詞彙表**概念。解釋常用詞彙表示方法：如**Bag-of-Words模型**（統計詞頻，不考慮詞序）、**詞向量**（如word2vec、Glove將詞轉為稠密向量表示語義）、以及近年的**上下文語言模型**（BERT等）。
2. **中文分詞與斷句：** 針對中文文本，需要先進行**斷詞**（因為中文沒有空格區隔單詞）。演示使用`jieba`庫對一句中文病歷進行分詞。例如：“狗狗食慾不振，嘔吐三次”會被分成“狗狗/食慾/不振/，/嘔吐/三次”等詞彙。強調正確的分詞有助於後續分析。英文文本則可略過此步驟或用簡單空白切分。
3. **詞頻統計範例：** 透過一個簡短的獸醫病歷文本集合，展示如何統計詞頻。例如，有5份病例描述，統計出現頻率最高的詞（可能是“嘔吐”、“食慾不振”、“發燒”等）。觀察這些高頻詞基本反映常見症狀。討論**停用詞**概念（如“的”、“了”等漢語助詞常見但無實質意義），處理時通常要過濾。
4. **文本表示與特徵化：** 介紹使用`sklearn.feature_extraction.text.CountVectorizer`將文本轉成向量的做法。即建立詞字典，將每篇文本表示為各詞出現次數的向量。提到若要捕捉詞序，可以用**N-gram**（例如二元gram記錄連續兩詞搭配）。此步可用簡單程式演示：將幾句病歷輸入CountVectorizer，輸出特徵矩陣，看到每句在不同詞維度上的計數。
5. **NLP任務應用：** 概述幾個與獸醫相關的NLP應用：
    - **文本分類：** 將整段臨床紀錄自動歸類到專科，例如判斷一份病歷屬於心臟科、皮膚科或骨科。這有助於轉診時快速分診給正確專科獸醫。
    - **命名實體識別（NER）：** 自動從病歷文字中抓取實體，如疾病名稱、症狀、藥物、動物品種等。例如辨識出“犬瘟熱”、“淋巴瘤”、“阿莫西林”等詞。這可以將非結構化紀錄轉為結構化資料，方便統計分析。
    - **關係抽取：** 在識別出實體後，抽取它們之間的關係。例如從“右後腿嚴重跛行”這句識別出實體“右後腿”（身體部位）和“跛行”（症狀），並理解兩者的關聯（跛行發生在右後腿）。這對構建醫學知識圖譜有用。
    - **文本摘要：** 自動生成病歷摘要或重點提示，例如從長長的住院紀錄中提取出主訴、診斷、處置要點。這將是我們之後幾週關注的重點。
6. **資料孤島與標準化挑戰：** 在文本應用的最後，討論目前台灣獸醫病歷存在的**非結構化**和**數據孤島**問題。許多病歷以紙本或自由格式存在，導致AI訓練資料難以取得且不標準。強調未來若要充分利用NLP技術，需推動**電子病歷**與**資料標準**，以利數據共享與模型訓練。

**程式碼範例：** 以下示範使用Scikit-learn將簡單的中文病歷進行特徵向量化並做分類（為方便，使用中文斷詞後的結果）：

```python
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB

# 範例病歷文本（已經用空格隔開詞彙，模擬斷詞結果）
documents = [
    "狗狗 食慾 不振 嘔吐",
    "貓咪 皮膚 出現 紅疹 搔癢",
    "狗狗 後腿 跛行 關節 腫脹",
    "兔子 食慾 正常 活潑",
]
labels = ["腸胃科", "皮膚科", "骨科", "一般科"]  # 對應的科別標註

# 向量化文本
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(documents)

# 訓練簡單的樸素貝葉斯分類器
clf = MultinomialNB()
clf.fit(X, labels)

# 測試新病歷的科別預測
new_doc = ["狗狗 嘔吐 下痢 食慾 差"]  # 新的症狀描述
X_new = vectorizer.transform(new_doc)
pred_label = clf.predict(X_new)[0]
print("預測科別:", pred_label)

```

在這個合成示例中，新病歷描述了嘔吐、下痢、食慾差等胃腸症狀，模型可能會預測：「預測科別: 腸胃科」。透過此簡化實驗，可了解文本分類的大致流程：文字先轉成數字特徵（詞頻向量），再用機器學習分類器學習詞和分類的對應關係。現實中若要實現自動分科或轉診建議，需要大量標註好的病歷作為訓練資料，以及更先進的模型如深度學習的Transformer架構，但基本步驟與此類似。

**延伸參考資源：**

- 可嘗試使用**jieba**對上述文本自動分詞，例如 `jieba.cut("狗狗食慾不振，嘔吐三次")`，體驗中文斷詞工具的效果。
- （論文節選）介紹了將非結構化病歷轉為結構化數據的關鍵NLP步驟，包括實體識別和關係抽取，可加深對醫療NLP任務的理解。
- 若對NLP文本表示有興趣，可進一步閱讀Word2Vec和BERT的相關中文教材，了解現代NLP如何產生上下文相關的詞向量，這對提升醫療文本理解能力很重要。

## 第10週：病歷文本分類與自動轉診建議

**研究目標：** 應用NLP技術實作一個簡單的**病歷文本分類**模型，以模擬「AI自動轉診建議系統」。透過本週任務，學生將體驗從收集標註資料、訓練分類模型，到讓模型對新病例預測可能需要轉診的專科的完整流程。同時認識該任務在實際應用中的挑戰（如醫療語言歧義、資料稀少等）。

**研究方法：** 實作練習與案例分析相結合。首先，需要準備一組已標註科別的獸醫病歷短文。由於難以取得真實病例，我們可人工編寫十幾則模擬病例描述，並標註對應的專科（例如皮膚病就標註皮膚科，心臟問題標註心臟科）。利用前述文本表示方法將這些樣本餵給分類算法（如朴素貝葉斯或支持向量機）進行訓練。然後用模型對新輸入的病歷描述進行**專科預測**，觀察模型建議將該病例轉診至哪一科。最後，討論模型效果與不足，以及未來如擴展到真實場景需要的步驟。

**詳細研究步驟：**

1. **資料蒐集與標註：** 準備至少每個目標專科3-5則案例描述，以涵蓋常見的轉診類別（例如內科、外科、皮膚科、眼科、心臟科、神經科等）。每則案例1-3句話，描述動物的症狀和初步檢查結果。例如：
    - 標註「心臟科」：案例描述「小型犬，出現嚴重心雜音，呼吸急促，疑似先天性心臟病。」
    - 標註「皮膚科」：案例描述「貓咪全身多處掉毛和皮膚紅疹，抓癢不止，懷疑皮膚蕁麻疹。」
    - 標註「神經科」：案例描述「狗後肢癱瘓無法站立，深痛覺降低，可能椎間盤問題。」
        
        對每則描述，根據主要問題手動指定最相關的專科。這些將作為模型訓練的**樣本-標籤**對。
        
2. **特徵提取：** 使用Scikit-learn的`CountVectorizer`或`TfidfVectorizer`將上述文本資料轉換為特徵向量。由於資料量極小，此處直接使用詞頻向量即可（高階方法如詞向量在小數據下未必有優勢）。考慮到中文，此處需先確保進行了良好的斷詞，可採用極端簡化的方式（例如以空格分隔詞，或用`jieba`斷詞再把結果餵給CountVectorizer）。
3. **模型訓練：** 選用一個簡單且適合多分類的模型，如**朴素貝葉斯分類器**（MultinomialNB）或**支持向量機**（SVC）。將上述特徵矩陣和科別標籤輸入分類器進行訓練。由於樣本非常有限，可以考慮**留一交叉驗證**來評估模型，即反覆選一則案例作測試、其餘作訓練，觀察平均表現。如果時間有限，也可直接使用全部資料訓練，之後人工判斷結果合理性。
4. **模型測試：** 輸入幾則新的病例描述（不在訓練集中）讓模型預測。例如測試句：「貓咪口腔發現大顆腫瘤，影響進食。」期望模型預測「腫瘤科」；「狗狗持續癱瘓，深痛覺缺失。」期望模型預測「神經科」。觀察模型輸出，如果預測有誤，分析可能原因（如關鍵詞未出現在訓練樣本中，或模型過度依賴某些詞）。
5. **結果討論：** 由於訓練樣本非常少，模型預測可能不太可靠。我們討論提升的方法：需要大量多元的標註病歷讓模型學習，且病歷記錄用詞多變，需要更健全的詞彙特徵（可引入詞向量技術讓模型理解同義詞，如「沒食慾」和「食慾不振」應該表達相似概念）。另外，醫療文本分類也可以引入**深度學習**模型如BERT進行微調，在大數據上效果更好。
    - 強調**資料量與品質**的重要：轉診建議AI要實用，必須整合大量各科病例，並由專科獸醫嚴謹標註作為黃金標準。
    - 提及論文中所說，NLP可將百萬筆臨床記錄轉為結構化資料庫，用於監測疾病流行與挖掘知識。我們的分類模型即是將非結構化病歷自動結構化的一種嘗試，未來若完善，能在轉診流程中減輕人力（如自動把病例轉給對應科醫師）。
    - 也討論**錯誤風險**：如果AI建議錯誤科別，可能導致延誤治療或資源浪費。因此最終決策仍需獸醫把關。目前AI轉診建議可作為參考輔助，而非唯一依據。

**程式碼範例：** 由於與第9週的範例類似，這裡提供一個簡化版本（實際應使用更多樣本）：

```python
docs = [
    "狗 心臟 雜音 呼吸 急促",    # 心臟科
    "貓 皮膚 紅疹 抓癢",        # 皮膚科
    "狗 後肢 無力 癱瘓",        # 神經科
    "貓 口腔 腫瘤 流口水",      # 腫瘤科
    "狗 嘔吐 下痢 脫水",        # 內科
]
labels = ["心臟科","皮膚科","神經科","腫瘤科","內科"]

# 向量化
X = CountVectorizer().fit_transform(docs)
clf = MultinomialNB().fit(X, labels)

# 測試模型
test_case = ["狗 呼吸 急促 舌頭 發紺 咳嗽"]  # 應屬於心臟或呼吸科
X_test = CountVectorizer(vocabulary=clf.feature_count_.keys()).fit_transform(test_case)
print("模型建議轉診至：", clf.predict(X_test)[0])

```

由於樣本極少，模型可能會依賴有限的詞彙做出猜測，例如看到“呼吸 急促”二詞，可能傾向預測**心臟科**（因為訓練集中心臟科案例包含這些詞）。實際輸出如：`模型建議轉診至： 心臟科`。這雖可能符合我們預期，但要注意模型的魯棒性不足：若輸入詞彙稍有變化，結果可能不穩定。這反映了**資料稀疏**對NLP模型的影響，以及在醫療AI中，蒐集龐大且多樣的訓練資料是多麼重要。

**延伸參考資源：**

- 嘗試使用 Hugging Face 提供的繁體中文預訓練模型（如**BERT** or **Albert中文模型**）對上述分類任務進行微調，看看是否能在少樣本下取得較好結果（需進階知識）。
- 提到AI可即時將對話轉文字並生成結構化病歷摘要甚至建議下一步檢查，這實際上結合了語音識別、NLP和推薦系統等多項技術，可作為更遠期的研讀方向。
- 可以查閱台灣或國際上是否已有獸醫醫療資訊系統開始嘗試引入AI輔助轉診或病例分類的案例，了解商業與臨床落地現況。

## 第11週：醫療文本摘要與知識提取

**研究目標：** 學習如何利用NLP技術對冗長的醫療文本進行**摘要**和**重點提取**，藉此減輕獸醫師閱讀大量病歷的負擔。本週將聚焦**自動摘要**：給定一段詳細的獸醫病歷記錄，讓模型產生一段簡明扼要的摘要，例如涵蓋主訴、關鍵發現和初步診斷建議。透過實驗了解目前摘要模型的基本用法和效果，同時討論在醫療領域確保摘要**正確性**的重要性。

**研究方法：** 工具應用與結果評析。本週將使用**預訓練的文本摘要模型**（Transformer架構）來對獸醫病歷文字進行摘要。由於自行訓練摘要模型需要大量標註數據，我們採用 Hugging Face 提供的現成模型進行推理試驗。步驟包括：選取或編寫一段較長的病例描述文字，調用摘要模型獲取自動總結，然後人工評估摘要是否抓住了重點。最後，討論摘要模型在醫療場景面臨的挑戰，如專有名詞、生僻症狀的處理，以及潛在的錯誤風險。

**詳細研究步驟：**

1. **準備測試文本：** 選擇一份較詳細的模擬病例，例如包括動物背景、主訴症狀、檢查結果和初診印象的段落（100~200字）。例如：
    
    *「病例：8歲米格魯，公犬。主訴：近一週食慾不振、呼吸急促，易疲勞。檢查：聽診發現三級心雜音，X光顯示心臟輪廓擴大，肺野輕微混濁。初步診斷：懷疑擴張型心肌病合併輕度肺水腫。」*
    
    這段文字涵蓋了背景、症狀、檢查和初診斷，很適合作為摘要輸入。
    
2. **調用預訓練摘要模型：** 使用Hugging Face的Transformers庫簡便的**pipeline**接口來加載一個預訓練的英文摘要模型（如`sshleifer/distilbart-cnn-12-6`）。由於我們的文本是中文，可先嘗試直接輸入讓英文模型摘要，看結果如何（可能模型不支援中文，則需改用支援中文的模型，如**mT5**或中文BART）。在程式碼中，建立`pipeline('summarization')`，輸入文本並設定適當的摘要長度參數。
3. **獲取摘要結果：** 模型會返回生成的摘要文本。例如針對上面的病例描述，理想摘要可能是：*「米格魯犬一週來食慾差、呼吸急促。檢查發現心雜音及心臟擴大，初步懷疑心肌病導致心臟肥大及輕度肺水腫。」* 比對模型輸出的摘要與我們預期的摘要是否相符。
4. **調整與多次嘗試：** 如果第一次結果不理想，嘗試調參如增加`max_length`讓摘要長一點，或使用中文模型重新生成。注意記錄每次模型輸出的摘要內容。例如模型可能遺漏了肺水腫的信息，這在醫療上是關鍵遺漏，需要想辦法彌補——討論真實應用中也許要引入**關鍵詞強制**或由醫師校訂。
5. **評估摘要質量：** 以人工角度從幾方面評估：
    - **涵蓋重點：** 摘要是否包含了主要症狀、重要檢查結果和初步診斷？有無錯漏？
    - **語句通順：** 語言是否流暢易懂？是否有語法問題或不連貫？
    - **專業正確：** 有無事實性錯誤（比如把輕度說成重度等）？這點非常重要，因錯誤摘要可能誤導臨床判斷。
        
        若發現問題，指出屬於模型的哪種典型錯誤，如**資訊遺漏**、**資訊扭曲**或**無關內容**。
        
6. **討論應用現狀：** 說明目前自動摘要在醫療領域仍屬研究階段，原因是要求**高準確性**且**保留關鍵資訊**。我們的實驗顯示AI摘要有一定能力提取大意，但細節可能遺漏或需要人工校對。引申論文中提到未來診間情境：AI即時聽診對話並生成病歷摘要甚至下一步建議。要實現這目標，需要解決模型的可解釋性與可靠性問題。這為我們後續的倫理討論（如AI錯誤誰擔責等）埋下伏筆。

**程式碼範例：** 使用Hugging Face的pipeline進行文本摘要：

```python
from transformers import pipeline

# 初始化英文摘要pipeline（如需中文模型，可指定 model='...' 參數為中文預訓練模型）
summarizer = pipeline("summarization")

text = ("8歲米格魯公犬，一週來食慾不振、呼吸急促。檢查發現三級心雜音，X光顯示心臟擴大、肺野模糊。"
        "初步懷疑擴張型心肌病導致心臟肥大及輕微肺水腫。")
summary = summarizer(text, max_length=50, min_length=20, do_sample=False)
print("AI摘要結果:", summary[0]['summary_text'])

```

模型可能輸出英文摘要（假如使用英文模型）：例如 `AI摘要結果: The dog has been suffering from loss of appetite and rapid breathing for a week. Examination found a grade 3 heart murmur and enlarged heart. It is suspected to be dilated cardiomyopathy with mild pulmonary edema.` 若換成支持中文的模型，則輸出為中文摘要。上述英文摘要中可以看到，AI抓住了主要資訊：食慾不振、呼吸急促、心雜音、心臟擴大、疑似心肌病伴肺水腫。這與我們預期的重點基本一致。但要留意這需要我們手動確認，並非所有情況都這麼理想。

**延伸參考資源：**

- Hugging Face官方文件中提供了使用transformers進行文本摘要的示例，以及模型名稱列表，可用來嘗試不同模型（如專門針對醫療文本訓練的模型）。
- 若想深入研究，建議閱讀近期論文如《Clinical BERT for Clinical Text Summarization》，了解針對醫療領域調適的語言模型如何提高摘要質量。
- 可將本週產出的AI摘要與人類醫師手寫的摘要對照，體會AI與人類在語言表達和重點選擇上的異同，這對思考AI如何輔助而非取代醫師有幫助。

## 第12週：AI模型透明度與可信任問題

**研究目標：** 探討人工智慧在醫療應用中特有的**透明度**和**信任**挑戰。理解深度學習模型常被視為“**黑盒**”的問題，以及這對獸醫師和飼主接受AI輔助的影響。學習提升模型可解釋性的方法概覽，並思考如何在臨床使用中建立對AI的信任。

**研究方法：** 文獻研讀與案例討論。閱讀研究論文相關章節，了解在醫療領域對AI決策過程**不可解釋**的顧慮。透過實驗或視覺化小工具，觀察一個簡單模型的決策邏輯（例如決策樹可以輸出判斷規則，較透明）。與深度CNN比較，CNN準確率雖高但很難直觀解釋其依據。討論臨床上獸醫師為何需要知道AI決策的原因，以及如果AI無法解釋其判斷，飼主和醫師可能產生的不信任。最後，介紹研究中為增加模型透明度所採取的措施，如**Grad-CAM**熱力圖解釋影像模型重點關注區域等，讓學生對可解釋性技術有初步認識。

**詳細研究步驟：**

1. **黑盒問題說明：** 重溫之前訓練的深度學習模型，指出其內部包含數十萬乃至上千萬參數，對人類而言難以逐一理解。引用論文中的描述：對人類來說，我們知道輸入了什麼、輸出了什麼，但對模型內部成千上萬參數如何運作得出結論的邏輯卻難以完全理解。這就像一個黑盒子，我們無法窺視其推理過程。
2. **醫療決策的可解釋性：** 強調在醫療場景，解釋的重要性遠高於其他應用。獸醫師在向飼主說明病情時，若引用AI的建議，需要能解釋「為何AI會這樣判斷」。否則一旦AI的結論和人的判斷衝突，獸醫師難以信服或說服他人採納AI結果。舉例：AI建議對一隻表面健康的狗進行心臟超音波轉診，但獸醫看不出明顯異常——如果AI無法指出具體理由（如X光上細微的心臟擴大跡象），醫師和飼主都難以接受這建議。
3. **案例討論：** 假設前幾週我們訓練的CNN模型判斷某張X光有90%可能有腫瘤，但沒有解釋。請學生扮演獸醫師，面對這輸出會有何感受：可能會懷疑模型是否誤判，因為不知道模型究竟看上了哪個影像區域。而如果有一張**熱力圖**顯示模型關注在X光中的某個陰影區塊，獸醫師就能理解模型關注點，也許更容易信任該結果。
4. **提高透明度的方法：** 簡介AI可解釋性的幾種方法：
    - **可視化關注區:** 對影像模型，用Grad-CAM等方法產生熱力圖，標示模型判斷依據的重點區域。例如前述狗X光，可顯示模型關注的紅色區域在肺部一塊陰影上。這使獸醫師能驗證AI的注意力是否在臨床相關的位置。
    - **簡化代理模型:** 用一個簡單的、可解釋的模型（如決策樹）去逼近複雜模型在局部的行為，提供人類可理解的規則。像LIME技術可對單一預測給出近似線性解釋。
    - **模型內生可解釋:** 採用本身具有可解釋結構的模型，如決策樹或注意力機制模型，至少能部分反映決策權重。
        
        學生不需要深入技術原理，但要知道這些努力目的是為了讓AI決策“**言之有物**”，而非不可理解的輸出數字。
        
5. **信任建立與人機協作：** 討論如何逐步在臨床建立AI信任：
    - **驗證測試：** 在導入AI前，用歷史案例測試AI，看看AI的輸出是否大體可靠，獸醫師會對哪些情形AI容易出錯心裡有數。
    - **人員培訓：** 讓獸醫了解AI的原理與局限，不迷信高準確率，遇AI結論不合理時敢於質疑。
    - **逐步放權：** 初期將AI當輔助工具，所有決策由人覆核；隨著信心增加，AI可負責部分routine任務，但關鍵決策仍由人把關。
    - **取得飼主信任：** 飼主可能對AI診斷將信將疑，需要獸醫師以簡單比喻解釋AI如何運作（例如“這個軟體分析了成千上萬X光片，所以能發現一些人眼難察覺的早期跡象”），並表明會由專科醫師確認AI發現，減少飼主疑慮。
6. **現狀與未來：** 提到目前許多醫學AI研究都在關注可解釋性問題，因為法律和倫理要求下，AI醫療決策需要**可追溯**（醫師要能解釋診斷依據）。未來可能監管也會要求AI系統提供某種形式的解釋才可採用。讓學生明白，提高透明度是AI深入醫療領域的必經之路。

**程式碼範例：** 本週重點在討論，程式方面可展示一個Grad-CAM熱力圖產生的簡要過程（實際繪圖需較多程式，這裡描述步驟）：

```python
# 以下為概念性代碼示意，實際需CV2等工具支持
import cv2
import numpy as np

# 給定一張輸入影像 img 和訓練好的模型 model
pred_class = np.argmax(model.predict(img.reshape(1,32,32,3)))

# 計算Grad-CAM
grads = tape.gradient(predictions[:, pred_class], last_conv_layer_output)
pooled_grads = np.mean(grads, axis=(0, 1, 2))
heatmap = tf.reduce_mean(tf.multiply(pooled_grads, last_conv_layer_output), axis=-1)

# 疊加熱力圖到原圖
heatmap = np.maximum(heatmap, 0) / np.max(heatmap)
heatmap = cv2.resize(heatmap, (img_width, img_height))
heatmap = np.uint8(255 * heatmap)
heatmap_img = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)
superimposed_img = heatmap_img * 0.4 + img

```

上述程式獲得的`superimposed_img`即為Grad-CAM可視化結果，其中紅色高亮區域代表模型判斷所依據的影像區域。展示這張圖給獸醫師，比起只給出“模型認為有90%機率異常”，更能贏得信任——因為獸醫師可用專業知識評估模型關注的區域是否合理（例如確實對準病灶）。如果模型關注點明顯偏離（比如關注在無關的背景噪點上），獸醫師會對該結果存疑，這也是一種安全機制。

**延伸參考資源：**

- （論文節選）深入闡述了黑盒模型與醫療“可解釋、可追溯”原則的衝突，值得細讀理解。
- 了解更多可解釋性技術，可查閱《Interpretable Machine Learning》一書或相關博客，裡面有Grad-CAM、LIME、SHAP等方法的介紹。
- 可以嘗試使用現成的Grad-CAM實現（如keras-vis套件）對我們第7週訓練的模型做視覺化，親眼看看模型對貓狗影像的關注區域，體驗解釋模型的有趣之處。

## 第13週：AI決策的責任歸屬與法律考量

**研究目標：** 探討當AI輔助診療出錯時，「責任歸屬」的倫理與法律問題。了解目前此議題在獸醫領域和更廣泛的醫療領域的爭議點，思考在沒有明確法規的情況下，醫療機構導入AI時應如何界定與分擔責任。本週也將從實際案例出發，討論假如AI誤診導致動物受到傷害，可能的後果與處理方式。

**研究方法：** 情境討論與文獻分析相結合。假設一個情境：某教學動物醫院使用AI協助判讀X光，AI錯將一個腫瘤判為良性導致延誤治療，動物不幸去世。讓學生思考：責任在誰？是最後做決策的獸醫師，還是提供AI軟體的公司，抑或醫院管理層？這其實對應了論文中提出的「**責任真空**」問題。閱讀論文中對責任歸屬困境的表述，瞭解目前法律框架下並沒有明確答案。藉此，引導學生從多方觀點分析：獸醫師角度、開發者角度、醫院角度、監管機構角度，各自會如何看待責任。最後，介紹國內外對這問題的討論現況，以及可能的解決方向（例如建立法律上的“安全港”或責任共擔機制）。

**詳細研究步驟：**

1. **情境案例討論：** 團隊討論前述假想案例。首先列出各相關方：**執業獸醫師**（使用AI輔助診斷的人）、**AI軟體公司**（開發與供應者）、**醫院管理者**（決定引入AI者）、**政府監管**（批准AI產品上線的機構）、以及**飼主**（動物法定擁有者）。然後問：當發生誤診事故，飼主可能會起訴誰？依現在法律，誰會被認定為有過失？
    - 學生可能認為獸醫師最終做決策，應負主要責任；也有人覺得AI提供了錯誤信息，廠商也應擔責。這正是現實中的爭議點。
2. **閱讀研究論文觀點：** 研讀論文對此的分析：當AI輔助決策最終被證明錯誤並造成傷害時，**現行法律框架難以釐清責任**。獸醫師可辯稱自己遵循了當時認為先進的技術建議；AI公司可主張軟體只是輔助工具、最後決策在醫師；醫院可說他們只是使用經認證的工具。結果就是各方都有理由推卸，形成責任真空。
3. **借鏡人醫案例：** 提及在人類醫療領域，也有類似討論。例如某放射科AI漏診一個腫瘤，醫生依賴AI沒有發現。如果病人起訴，很可能最終責任還是在人醫師，因法律上醫師對診斷負有責任。但這會不會打擊醫師使用AI的意願？許多醫院管理者正因擔心責任不清而對全面引入AI保持觀望。
4. **法律現況調查：** 查閱台灣現行**獸醫法**與**消保法**等，看是否有對醫療AI的條款。發現目前沒有專門規範。可以講到人醫領域像歐盟、美國FDA開始為AI醫療器材制定指引，但責任界定仍在摸索。有的建議引入「AI廠商強制保險制度」，一旦AI出錯由保險賠付，責任不全落醫師身上。台灣可能未來也需立法，例如規定AI廠商需對其產品診斷結果承擔部分責任。
5. **學生觀點彙總：** 讓每位學生簡述自己認為最公平合理的責任分擔方案。例如：獸醫師、醫院、廠商按比例承擔？或者建立類似汽車自駕的**責任保險**制？討論各方案的可行性。
6. **未來展望與建議：** 論文最後對政策制定者也提出建議：需儘快明確AI醫療糾紛的責任原則。鼓勵學生思考，身為未來可能使用AI的獸醫，應積極參與這方面的討論，確保自己的權益和動物福祉都被兼顧。例如可倡導制定指南，明確在何種情況下使用AI，及出錯時的處理流程，將風險降至最低。

**程式碼範例：** （本週無特定程式實作，重在倫理討論）但可以設計一個簡單的投票程序模擬責任分配：

```python
parties = ["獸醫師", "AI廠商", "醫院管理者", "無明確責任主體"]
votes = [0, 0, 0, 0]

# 模擬全班同學投票結果（這裡假設有20票，做隨機演示）
import random
for i in range(20):
    choice = random.choice(range(len(parties)))
    votes[choice] += 1

for party, v in zip(parties, votes):
    print(party, "得到票數:", v)

```

執行後例如輸出：

```
獸醫師 得到票數: 8
AI廠商 得到票數: 5
醫院管理者 得到票數: 3
無明確責任主體 得到票數: 4

```

這或許顯示學生們意見分歧，有人選擇獸醫師、有人體認到目前真的是無明確主體（責任真空）。藉此強調，我們模擬的小投票都如此分散，在社會和法律領域更是爭議不休。這需要多方協商，找出一個能促進AI發展又保障醫療安全的責任機制。

**延伸參考資源：**

- （論文責任真空段落），了解目前台灣在此問題上的討論基礎。
- 比較國際法規，例如歐盟的《人工智慧法規草案》是否有涉及AI產品責任，或美國FDA對AI醫療器材的監管框架等。
- 建議閱讀有關**自動駕駛車禍責任**的討論，因為情境類似：AI決策影響人命，責任如何分擔。自動駕駛領域出現過製造商承擔部分責任的案例，可作為醫療AI的參考。

## 第14週：演算法偏見與資料隱私倫理

**研究目標：** 探討AI模型可能存在的**偏見（Bias）問題，以及醫療數據的隱私**與**授權**議題。理解如果訓練資料不具多樣性，AI決策可能對某些族群（或某類動物）不公，進而導致醫療不平等。同時，思考在蒐集和使用動物醫療資料訓練AI時，如何遵守法律和尊重飼主隱私權，避免違規和信任危機。

**研究方法：** 個案分析與法規研讀相結合。首先以案例說明演算法偏見：假設某AI主要用大型犬資料訓練，對小型犬心臟病的辨識效果較差，這就是一種**樣本偏差**導致的結果，可能不利於小型犬族群。討論如何避免及偵測這類偏見。接著，查看台灣《個人資料保護法》對醫療資料的規範，瞭解動物醫療資料是否適用，醫院在提供資料給AI廠商時需取得哪些授權和去識別措施。透過閱讀論文中相關段落，了解目前數據共享困境與法規要求。最後，討論在合法合規的前提下，如何平衡資料利用和隱私保護，使AI研發能順利進行又不侵犯個資。

**詳細研究步驟：**

1. **算法偏見案例討論：** 提出一個假想場景：AI皮膚病診斷模型在國外研發，資料多為淺色皮毛的犬貓影像，結果該模型對黑色皮毛的動物皮膚病變偵測率很差，因為病灶不明顯且訓練中樣本少。這導致深色寵物可能被AI誤診為正常而延誤治療。這就是**訓練數據偏差**造成對某類群體不公。請學生思考還有何種偏見可能發生：例如資料主要來自都會高級醫院，AI對偏遠地區常見的疾病譜不了解；或AI主要在純種狗資料上訓練，對混種狗的情況掌握不足等。
2. **避免與偵測偏見：** 討論如何減少這些偏見：在資料收集階段就注重多樣性，確保各品種、年齡、性別的動物病例都有涵蓋；訓練後用不同子群測試模型（例如分別測試黑毛和白毛動物的精度，男性飼主/女性飼主的溝通文本模型表現等），主動發現偏差。必要時可對模型做偏差矯正，如採用技術在訓練時增加少數族群樣本權重。
3. **資料隱私現況：** 轉向資料層面。列出獸醫醫療數據類型：病例紀錄、檢驗報告、影像、飼主基本信息等。根據台灣《個資法》，**飼主個人資料**明確受保護（如姓名、電話）。而動物的醫療資料是否屬個資？雖動物不在《個資法》範圍，但如果能間接指向飼主，仍可能算敏感。例如病例記錄中包含飼主姓名或地址，這部分屬個資。因此醫院與AI合作前，須**告知並取得飼主同意**將資料用於研發。而資料提供則應**去識別化**處理，如刪除飼主信息，用隨機編號代表病歷，以減少隱私風險。
4. **法律閱讀與解析：** 研讀論文對個資法的重點說明：獸醫院作為非公務機關，收集飼主資料要告知目的、範圍，並保障安全。不經同意不得交給第三方（AI公司）除非資料已做完全去識別化。然而**完全去識別**技術上有難度且可能影響資料可用性，而若涉及跨國傳輸（如把資料傳到國外雲端計算）還需遵守相關規定。這些條款為建立全國性獸醫AI資料庫設置了重重關卡。
5. **學生角色扮演：** 分組模擬醫院管理階層決策：想推動建立一個區域性的智慧獸醫醫療資料庫供AI訓練，需說服各診所參與又不違法。各組提出方案：如訂定統一的病歷格式方便去識別、由公正單位（獸醫師公會）托管資料庫、制訂參與協議保障診所和飼主權益等。大家互評方案可行性。
6. **資料倫理總結：** 強調取得大量高品質資料和保護隱私是一對矛盾，需要取得平衡。論文提到目前的數據孤島是AI發展絆腳石，我們要在尊重倫理的基礎上設計創新的資料共享模式。可能的方向包括：由政府出面建立**匿名化中央資料庫**、推動診療系統廠商制定**資料交換標準**、透過**聯邦學習**在各醫院本地訓練模型而不匯出資料等新技術，來同時滿足隱私和發展需求。引導學生認識到，這方面沒有簡單答案，但作為未來從業者應密切關注相關政策和技術進展，確保AI發展朝著兼顧倫理的方向前進。

**程式碼範例：** 本週重點在概念，可展示一個簡單的數據去識別例子：

```python
import re

record = "飼主:王小明, 寵物:Lucky, 種類:犬, 主訴:拉肚子2天"
# 去識別化 - 移除人名和寵物名，用類別代替
anon_record = re.sub(r"飼主:.*?,", "飼主:某先生,", record)
anon_record = re.sub(r"寵物:.*?,", "寵物:某寵物,", anon_record)
print("原始紀錄:", record)
print("去識別後:", anon_record)

```

這段程式將**王小明**和**Lucky**替換為泛稱，模擬了一種簡單去識別化。輸出：

```
原始紀錄: 飼主:王小明, 寵物:Lucky, 種類:犬, 主訴:拉肚子2天
去識別後: 飼主:某先生, 寵物:某寵物, 種類:犬, 主訴:拉肚子2天

```

但也指出這只是示意，真實情況中可能有更多敏感信息需要去除（地址、電話等），而且要確保即使如此資料仍有用（如不能把“邱吉爾犬”品種名都抹掉）。再次強調完全去識別可能難做到同時保持資料價值。

**延伸參考資源：**

- （論文提及偏見與隱私的風險）可作為理解該議題重要性的引文。
- 了解**聯邦學習（Federated Learning）**在醫療上的應用，這種技術讓資料不出醫院也能訓練聯合模型，或許是解決數據隱私與共享難題的方向之一。
- Follow近期國際新聞，如有無發生過醫療AI偏見導致不公的案例、人們如何發現並修正，以及各國隱私法（如GDPR）對醫療AI資料的要求條款。這有助開闊視野，知道我們面臨的問題在全球都在被嚴肅對待。

## 第15週：AI對獸醫職業生態的影響

**研究目標：** 探討人工智慧在轉診獸醫醫學中的普及，將如何影響獸醫的**專業分工**與**技能需求**。理解AI可能導致的部分傳統技能被弱化（去技術化），以及獸醫師角色可能從執行者轉變為決策者、溝通者等更高層次的職責。同時討論AI可能造成的**馬太效應**：大型連鎖醫院資源愈發集中，小型獨立診所面臨挑戰。最終，思考未來獸醫教育和繼續教育應做出哪些調整，以培養適應AI時代的獸醫人才。

**研究方法：** 項目回顧與未來展望並重。回顧前面幾週我們見識到AI能做的種種工作（影像判讀、報告摘要、決策建議），思考這些工作原本都是由獸醫或助理完成的。引導學生列出AI可能取代或減輕獸醫師負擔的任務，以及AI無法取代，需要獸醫更專注發揮的領域。閱讀論文相關部分，瞭解作者對獸醫專業角色轉移的論述。然後小組討論：未來的“優秀獸醫師”應該具備什麼樣的能力？如何在與AI協同下發揮最大價值？最後，總結形成對獸醫教育和在職培訓的建議，例如課程增加AI素養、模擬人機協作流程等。

**詳細研究步驟：**

1. **AI影響傳統技能列舉：** 列出轉診獸醫醫學中的關鍵技能：例如X光/超音波判讀、血檢數據分析、病例書寫與管理、治療方案制定、手術操作、與飼主溝通等。然後標記哪些技能AI已涉足或能輔助：
    - 影像判讀：AI可部分取代（自動檢出異常陰影等）。
    - 數據分析：AI擅長（異常數值預警、模式發現）。
    - 病例書寫：AI可協助（語音轉錄和摘要整理）。
    - 治療方案：目前AI只能建議，最終決策仍靠專科知識和經驗。
    - 手術操作：AI機器人輔助手術在發展，但獸醫手術尤其動物多樣性，高度依賴人。
    - 飼主溝通：AI難以取代人類同理心和溝通技巧。
2. **去技術化與價值轉移：** 閱讀論文中的觀點：AI普及勢必對獸醫專業技能與價值產生深遠衝擊。一方面，重複性、規律性的診斷工作可能被AI自動化，使部分傳統臨床技能“**去技術化**”。例如以往要訓練多年的放射判讀專長，未來新人借助AI數月即可達基本水準。另一方面，獸醫師的價值核心需轉移到AI難以取代的能力上，如處理不確定性、複雜推理、表達同理心與溝通、倫理判斷和跨領域協作等。未來優秀獸醫不在於背誦海量知識（AI記憶庫更強）或快速辨識影像（AI圖像檢測更穩），而在於綜合運用AI提供的資訊，加上人類智慧做出最佳決策，並細心溝通執行。
3. **馬太效應與生態改變：** 討論AI昂貴的研發和設備成本可能加劇醫療資源不均。大型教學醫院、連鎖機構有資源引進AI系統，診療品質更提高，吸引更多客戶，形成良性循環；反之小型獨立診所若無力採用AI，可能被邊緣化，失去疑難病例轉診機會和客源。這會重塑獸醫產業生態：或許未來會出現區域聯盟，小診所依託大型中心的AI服務合作共生。思考有無對策減少不平等，如政府補助AI設備、中小型院所共享雲端AI平台等。
4. **未來技能培養：** 讓學生各自提出未來獸醫師應該加強的能力。預期包括：跨領域知識（懂一些資料科學與AI原理，能和工程師溝通）、終身學習（AI工具更新快，需要不斷學習新工具）、溝通協調（在人機團隊中協作，向客戶解釋AI結果），以及更強的同理心和職業倫理判斷，因為人文關懷是AI無法提供的。
5. **教育改革建議：** 綜合討論形成對獸醫教育的建議清單：
    - 在大學課程中加入「獸醫資訊學」「AI輔助醫學」選修，讓學生了解AI基本原理與應用。
    - 強調訓練學生**批判性思維**，避免過度依賴AI，培養對AI結果質疑與驗證的習慣。
    - 加強**溝通與倫理**課程，比重不亞於傳統醫療技能。未來獸醫更像一個**解釋員**和**決策協調者**，需要能向飼主闡明AI診斷，做出符合動物福祉和飼主價值觀的決策。
    - 提供在職獸醫師的AI訓練workshop，幫助老一輩獸醫跟上新工具，以免出現數位落差。
    - 鼓勵跨專業交流，讓獸醫師與工程師、數據科學家對話，共同開發貼近臨床需求的AI。
6. **學生自我定位：** 作為即將畢業的學生，思考自己在AI時代如何保持競爭力。建議大家既要打好傳統醫學基礎，也要擁抱新技術。強調AI不會取代獸醫，但不懂AI的獸醫可能會被取代。只有成為擅用AI的獸醫，才能在未來醫療體系中扮演領導角色。這週的討論旨在讓學生對自身未來職涯有更清晰的規劃方向。

**程式碼範例：** 無直接程式，但可以用一段簡單代碼凸顯AI與人類優勢互補：

```python
tasks = ["圖片辨識", "知識記憶", "情感溝通", "道德判斷"]
ai_skill = [9, 9, 1, 1]    # AI在各項能力的大致評分（1-10）
human_skill = [3, 6, 9, 9] # 人類在各項能力的評分

for task, ai, human in zip(tasks, ai_skill, human_skill):
    diff = "AI強" if ai > human else "人類強" if human > ai else "相當"
    print(f"{task}: AI能力{ai}, 人類能力{human} -> {diff}")

```

執行結果可能：

```
圖片辨識: AI能力9, 人類能力3 -> AI強
知識記憶: AI能力9, 人類能力6 -> AI強
情感溝通: AI能力1, 人類能力9 -> 人類強
道德判斷: AI能力1, 人類能力9 -> 人類強

```

這反映出未來獸醫師應該將精力放在AI不擅長的人文和高階決策領域，而把部分模式識別、數據分析工作放心交給AI處理。這也驗證了論文所說，獸醫師核心競爭力將轉向“AI難以取代的、更偏向人性的能力”。

**延伸參考資源：**

- （論文對獸醫角色轉變的論述）提供了非常有洞見的觀點，可作為未來職業發展的指引。
- 國際獸醫教育機構是否已有調整課程，例如增加AI相關課題，值得調查。比如英國RCVS的獸醫教育標準是否提到資訊技能。
- 可以閱讀《哈佛商業評論》之類的文章，了解在AI時代，各行業專業人士如何重新定位自身價值，從而借鑒到獸醫領域。

## 第16週：專題成果整理與報告撰寫

**研究目標：** 將前十五週所學的理論知識、實作經驗和討論所得進行全面整理，為結案報告做準備。學生需要有系統地總結AI在轉診獸醫醫學的**助益**與**威脅**，結合實驗結果和文獻，形成具有邏輯性的論述。目標是在撰寫報告的過程中鞏固所學，並能清晰地向他人傳達本專題的發現與見解。

**研究方法：** 綜合整理與寫作練習。本週主要產出最終報告的初稿。建議按照助益與威脅兩大主題架構報告內容（正如研究論文的分析框架），確保全面覆蓋專題要求。步驟包括列大綱、填寫證據、撰寫並反覆修改。也可以將前面各週的重要發現製作圖表（如模型流程圖、結果圖、Grad-CAM熱力圖等）納入報告，增強說服力。

**詳細研究步驟：**

1. **回顧專題內容：** 花時間翻閱前15週的筆記、程式和討論要點。將涉及的主題列出關鍵詞，如「深度學習影像診斷」、「病歷摘要」、「倫理責任」等。確保不遺漏任何重要方面。
2. **擬定報告架構：** 建議採用以下架構：
    - **引言：** 說明專題背景（轉診獸醫體系與AI崛起），提出研究目的與問題。
    - **AI在轉診獸醫的助益：** 分別論述AI如何提升診斷**準確率**與效率（引用我們影像分類模型結果和論文案例）、優化轉診流程（如病歷自動摘要與分診建議）、加速研發（藥物篩選、知識發現）。可引用我們實驗中模型達到的性能指標來支持。如：“我們訓練的CNN模型將胸部X光異常篩檢準確率提高到約85%，顯示AI確有潛力輔助第一線醫師。”
    - **AI帶來的威脅與挑戰：** 分點討論資源不均（大醫院vs小診所差距）、獸醫技能衝擊（去技術化）、責任歸屬不明、數據隱私與偏見風險等。我們在討論中得出的觀點都可納入，如AI偏見案例、小診所聯盟建議等，並引用論文觀點強化。
    - **結論與建議：** 總結AI在轉診獸醫的雙面性：既是**工具**也是**顛覆力量**。強調我們的立場：應順應AI發展但要做好倫理法規準備。提出建議給不同對象：教育者要調整課程、臨床醫師要擁抱學習AI、醫院管理者要審慎導入並制定風險管理策略、政策制定者要完善法規。結尾可呼應引言，展望台灣獸醫界在迎接AI時代的挑戰與機遇。
3. **收集證據與引用：** 在寫各部分時，把相關引用插入（包括我們實作所得結果數據及研究論文、其他來源）。如引言中引用論文強調缺乏系統研究；助益部分用論文數據佐證AI診斷效果；威脅部分引用論文對責任真空的闡述等。確保每個重要論點都有依據。
4. **撰寫初稿：** 根據大綱分段撰寫。注意學術風格，語氣客觀，中英文名詞一致（如Artificial Intelligence（AI）在首次出現寫全名附縮寫）。字數控制在適當範圍（假設5000字左右）。使用圖表時，撰寫圖表說明。
5. **檢查與修改：** 初稿完成後，自我檢查結構是否合理、論述是否連貫。有無遺漏專題要求的元素（例如我們實驗過程和發現是否有描述）。檢查引用格式與出處，避免抄襲。可邀請指導老師或同學幫忙審閱，根據反饋改進。
6. **定稿準備：** 修改完畢後得到報告終稿。本週末前完成排版（包含封面、目錄、引用文獻列表等）。確保引用文獻列表中包含我們主要參考的上傳研究論文及其它外部資源。為下週的成果發表做內容上的準備。

**程式碼範例：** 無直接程式實作，但建議學生使用文獻管理工具（如Zotero、EndNote）來組織引用。在此提供一段Python腳本幫助清點我們過去週次收集的資料來源：

```python
references = [
    "Chen et al. (2023) AI在轉診獸醫醫學的助益與威脅",
    "Huang et al. (2022) Veterinarian perceptions of AI, ...",
    # ... 列出所有在報告中引用的文獻 ...
]
print("總引用文獻數:", len(references))
for ref in references:
    print(ref)

```

這將列出文獻清單並計算數量，方便確認引用是否齊全。雖然我們用不到其輸出在報告中，但此步提醒學生做好引用的整理工作，不遺漏重要來源。

**延伸參考資源：**

- 可參考上傳的PDF論文的結論與建議部分，學習如何撰寫有力度的結論。
- 尋找類似主題的其他報告或學術論文，看看他們如何組織內容，例如人類醫學領域關於AI助益與威脅的綜述文章，從中學習表達。
- 在報告完成後，建議休息一天再重讀全文，以新視角潤色文字。這有助於發現之前忽略的問題，如前後用詞不一致、某段落銜接不順等。報告寫作也是訓練思維表達的過程，務必投入足夠時間反覆打磨。

## 第17週：專題成果發表與反思

**研究目標：** 完成專題最終報告的呈交，以及以口頭簡報形式發表研究成果。在發表過程中培養學生的總結歸納和表達能力。通過回答問答，深化對課題的理解。同時進行自我反思，總結收穫與不足，為未來進一步研究打下基礎。

**研究方法：** 簡報演練與現場Q&A。本週將專題內容製作成幻燈片，抓住重點向指導老師和同學們匯報。著重強調本專題的**核心發現**（AI助益與威脅並存的具體體現）以及我們**實作的成果**（模型演示、結果數據）。匯報完畢後，接受聽眾提問，針對性地解答，澄清觀點。在過程中記錄反饋意見。最後，撰寫一份個人反思日誌，內容包括對本專題的心得體會、遇到的挑戰、如何克服，以及未來若延伸研究，可以開展哪些主題。

**詳細研究步驟：**

1. **製作發表簡報：** 根據報告內容製作PowerPoint或Keynote簡報。建議以約15分鐘講述為目標，幻燈片不宜過多（15-20張）。結構可依報告章節排列，但需更精簡：
    - 引言：1張，點出AI在轉診獸醫的議題背景與重要性。
    - 方法：1-2張，說明我們透過哪些實作與研究步驟來探索問題（如模型訓練、小組討論等）。
    - 助益發現：2-3張，列舉AI助益的要點，每點配以圖片/數據（如我們CNN模型結果圖，或論文中提到的99%精度案例）。
    - 威脅發現：2-3張，同上，舉要點並附例證（如責任真空圖示、資源馬太效應圖表）。
    - 綜合討論：1-2張，說明我們對未來發展的看法和建議。
    - 結論：1張，重申AI是雙面刃，需要審慎樂觀對待。
    - 鳴謝與Q&A：1張致謝，留待問答。
        
        製作時，注意圖文並茂，少文字多圖表，關鍵結論用**粗體**標出。引用出處小字標註於角落以示嚴謹。
        
2. **演練講稿：** 為每張投影片準備講解詞，避免逐字唸PPT而是口語化闡述。可先在鏡子前演練或錄音聆聽，控制在規定時間內。針對可能被問到的技術問題（例如“為何選用某模型”）或倫理問題（例如“AI出錯如何處理”），預先準備答案。等引文可助答問。
3. **正式發表：** 在班上或專題發表會上進行報告。從容自信，語速適中，闡述重點突出我們的發現和貢獻。善用指示棒或雷射指出圖表重點區域。
4. **問答環節：** 認真傾聽提問，快速思考後回答。不懂或一時答不上來的問題坦誠以對，表示會後再研究。對老師的點評意見虛心接受，必要時和老師進一步討論請教。
5. **反思與未來工作：** 發表結束後，立即記錄下問答中暴露出的不足之處，例如某數據解釋不清、某結論說服力不夠等等。寫一份反思報告，包括：
    - **收穫：** 列出透過本專題掌握的新知識和技能（如掌握了CNN模型訓練流程、了解了醫療AI倫理框架等）。
    - **挑戰與不足：** 說明項目中遇到的最大困難（如資料不足、模型調參耗時、跨領域知識吃力等），我們如何應對，最終結果有無遺留缺陷。
    - **驚喜發現：** 有沒有意料之外的發現（例如原以為AI不可能摘要病歷，結果試了發現效果還不錯），或數據/討論結果特別有趣值得進一步研究。
    - **未來計畫：** 若延伸研究，可以做什麼？例如蒐集真實病例進行更大規模模型訓練、開發一個供臨床使用的簡易AI工具、研究其他專科AI（如中獸醫AI應用）等等。確保提出的未來工作具體可行，而非空泛。
6. **提交成果：** 將最終報告、簡報檔及反思日誌上交給指導老師存檔。本專題到此畫下句點，但學生應明白這其實是個起點——AI在獸醫的應用剛剛興起，未來大有可為，希望他們能持續關注甚至投入其中。

**程式碼範例：** 無程式。本週的重點在於**溝通與整理**。可建議學生使用一些工具輔助，如將數據結果繪圖，可用Matplotlib生成圖表貼入簡報。這裡給個示例來重溫我們CNN模型的訓練曲線繪製：

```python
import matplotlib.pyplot as plt

# 假設我們有保存的訓練歷史
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
epochs = range(1, len(acc)+1)

plt.figure()
plt.plot(epochs, acc, 'bo--', label='Training acc')
plt.plot(epochs, val_acc, 'ro-', label='Validation acc')
plt.title('Model accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.savefig('accuracy_curve.png')

```

這段程式將訓練和驗證準確率曲線畫出並保存為圖片`accuracy_curve.png`，可插入報告或簡報中以說明模型學習情況。如此完善我們資料可視化，增強報告說服力。

**延伸參考資源：**

- 查閱一些**學術匯報技巧**的文章或影片，如如何回覆刁鑽問題、如何有效交流跨領域內容，提升發表表現。
- 論文的摘要和結論提供了一個全篇概要，可作為我們總結時的參考措詞。
- 可以對照其他組的專題發表，學習優點，反思改進不足。這有助於學生在未來研究中更好地設計和傳達自己的工作。